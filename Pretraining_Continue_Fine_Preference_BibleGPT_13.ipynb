{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joshuwaifo/A-Bible-Pre-trained-Transformer-Model/blob/main/Pretraining_Continue_Fine_Preference_BibleGPT_13.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LLM Evaluation\n",
        "\n",
        "LMSYS ChatBot Arena\n",
        "- Crowdsourced\n",
        "- Pairwise ranking\n",
        "\n",
        "Using LLM as a judge:\n",
        "- For example GPT-4\n",
        "- Score between 0 and 100 on model responses"
      ],
      "metadata": {
        "id": "tHwPBWb3dqH_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pretraining from scratch\n",
        "# Expensive, almost never necessary\n",
        "# Research or Big company\n",
        "\n",
        "# Continued pretraining\n",
        "# Starting from a foundation model\n",
        "# Add knew knowledge\n",
        "\n",
        "# Finetuning\n",
        "# Special use cases\n",
        "# Following instructions\n",
        "\n",
        "# Preference finetuning\n",
        "# Improving helpfulness and safety\n",
        "# Especially when developing a chatbot"
      ],
      "metadata": {
        "id": "OsDBpBP9dumN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pretraining\n",
        "- Llama 2 Foundation models\n",
        "- (language)\n",
        "\n",
        "Continued Pretraining\n",
        "- Code training\n",
        "- Infilling code training 500B\n",
        "- (code)\n",
        "\n",
        "Continued Pretraining\n",
        "- Python code training 100B (python code)\n",
        "=> Code Llama - Python\n",
        "- Long context fine-tuning (longer context)\n",
        "=> Code Llama\n",
        "\n",
        "Finetuning\n",
        "- Instruction Fine Tuning (instruction dataset)\n",
        "=> Code Llama-Instruct\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gkqO3aL9dt9u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lightning AI studio"
      ],
      "metadata": {
        "id": "ElEhXArBfJUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chapter 1\n",
        "\n",
        "- Contextual analysis\n",
        "\n",
        "- Question answering\n",
        "\n",
        "- Transformer architecture\n",
        "\n",
        "- Contexts, patterns, nuances\n",
        "\n",
        "-"
      ],
      "metadata": {
        "id": "wPaqn8mQgnp7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LLM\n",
        "# Understand\n",
        "# Generate\n",
        "# Respond\n",
        "# To human like text\n",
        "\n",
        "# Next word prediction task\n",
        "# Next image or video frame prediction task\n",
        "\n",
        "# Understand context, structure and relationships within text\n",
        "# Understand context, structure and relationships within images or video frames\n",
        "\n"
      ],
      "metadata": {
        "id": "VISnLVnyhbOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transformer\n",
        "\n",
        "- Pay selective attention to different parts of the input\n",
        "- Use method to then make predictions\n",
        "\n",
        "\n",
        "- Multiverse: multihead attention\n",
        "- Gravity: attention\n",
        "- Position in world/earth: positional encoding\n",
        "\n",
        "Graph\n",
        "- Communicate: (multi head) attention\n",
        "- Compute: MLP\n",
        "\n",
        "Swin transformer"
      ],
      "metadata": {
        "id": "o58-C1ITh9Q2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generative Artificial Intelligence\n",
        "\n",
        "# Understanding language, visuals, sounds\n",
        "# Recognising patterns\n",
        "# Making decision\n",
        "\n",
        "# AI: Systems with human like intelligence\n",
        "# Machine Learning: Algorithms that learn rules automatically from data\n",
        "# Deep Learning: Machine Learning with neural networks consisting of many layers\n",
        "\n",
        "# Large language models: Deep neural network for parsing and generating human-like text\n",
        "# GenAI: involves the use of deep neural networks to create new content, such as text, images, or various forms of media\n",
        "\n",
        "# Minimising errors in predictions on a variety of datasets"
      ],
      "metadata": {
        "id": "K7ukG08TjRtQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "AI categories\n",
        "\n",
        "- Machine Learning -> Deep Learning\n",
        "- Rule-based systems\n",
        "- Genetic algorithms\n",
        "- Expert systems\n",
        "- Fuzzy logic\n",
        "- Symbolic reasoning"
      ],
      "metadata": {
        "id": "QDIuRdTwk-wi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ptt5x-9UlM0f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}