{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOsTjvEnUtmEEkpAsu1x6lc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joshuwaifo/A-Bible-Pre-trained-Transformer-Model/blob/main/NASB_Bible_Tokenised_BibleGPT_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preliminaries:\n",
        "\n",
        "Download the Bible text file nasb (dataset)\n",
        "\n",
        "Open the nasb.txt file\n",
        "\n",
        "Read in all the text as a string\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kswH2ynCsogq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gz-CEIz4sWlg",
        "outputId": "9348a3f0-a568-4247-b0c0-8d3432279eb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-08-05 11:02:55--  https://raw.githubusercontent.com/tushortz/variety-bible-text/master/bibles/nasb.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4685837 (4.5M) [text/plain]\n",
            "Saving to: ‘nasb.txt.1’\n",
            "\n",
            "nasb.txt.1          100%[===================>]   4.47M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2024-08-05 11:02:55 (52.9 MB/s) - ‘nasb.txt.1’ saved [4685837/4685837]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/tushortz/variety-bible-text/master/bibles/nasb.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('nasb.txt', 'r', encoding='utf-8') as f:\n",
        "  text = f.read()"
      ],
      "metadata": {
        "id": "hi7M7lxksoFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"length of dataset in characters: \", len(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrpusQG9tF8x",
        "outputId": "e15997fd-9031-4342-f05f-8e78ffa9bbe9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of dataset in characters:  4623633\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Just under 5 million characters in nasb.txt file\n",
        "\n",
        "Get a sorted list of unique string characters that are in the text\n",
        "\n",
        "Vocabulary size is the number of these unique characters = 78 in total here"
      ],
      "metadata": {
        "id": "l7ESeHXWtXnr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print(text[:1000])\n",
        "\n",
        "chars = sorted(list(set(text)))\n",
        "vocabulary = chars\n",
        "vocab_size = len(chars)\n",
        "print(''.join(chars))\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AW3_Bm3ytU7N",
        "outputId": "87fcb3db-6a31-4950-a53d-af8622a2a986"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " !\"'()*,-.0123456789:;?ABCDEFGHIJKLMNOPQRSTUVWXYZ[]abcdefghijklmnopqrstuvwxyz\n",
            "78\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(vocabulary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LFU8VTqt5R6",
        "outputId": "9b5520f6-b96c-45bf-c7a4-34fcc2397b66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\n', ' ', '!', '\"', \"'\", '(', ')', '*', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Strategy to tokenise the input text\n",
        "\n",
        "Tokenise = Convert raw text string to sequence of integers\n",
        "\n",
        "Here, simply convert individual characters into integers as this is a character level model\n"
      ],
      "metadata": {
        "id": "ducpNw3GuPl0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "encoder: (raw) input to tensor (each element in the tensor is an integer between 0 and vocabulary size - 1)\n",
        "\n",
        "decoder: tensor to (reconstructed) input\n",
        "\n",
        "Method:\n",
        "\n",
        "Iterate over all the characters in the vocabulary\n",
        "\n",
        "Create a lookup table\n",
        "\n",
        "To encode a string\n",
        "\n",
        "Translate all the characters in the string individually\n"
      ],
      "metadata": {
        "id": "4-FSgie5thEe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# simple tokenisation scheme index of sorted vocabulary (as this is character level)\n",
        "\n",
        "\n",
        "# lookup tables: characters/tokens to integers/vectors and vice versa\n",
        "characterToken_to_scalarTensor = { character : index for index, character in enumerate(vocabulary) }\n",
        "scalarTensor_to_characterToken = { index : character for index, character in enumerate(vocabulary) }\n",
        "\n",
        "# in case of issues down the line\n",
        "stoi = characterToken_to_scalarTensor # string to integer\n",
        "itos = scalarTensor_to_characterToken # integer to string\n",
        "\n",
        "# takes in a string\n",
        "# outputs a list of integers (list of scalar tensors)\n",
        "# scalar tensor example = 23\n",
        "encode = lambda string: [ characterToken_to_scalarTensor[character] for character in string ]\n",
        "\n",
        "# takes in a list of scalar tensors\n",
        "# outputs a string\n",
        "decode = lambda vector: ''.join([ scalarTensor_to_characterToken[scalarTensor] for scalarTensor in vector ])\n",
        "\n",
        "\n",
        "print(encode(\"hii there\"))\n",
        "print(decode(encode(\"hii there\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5laHBN1tSdc",
        "outputId": "66f636ce-3b4a-4a00-d930-0bdc5a0bd212"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[59, 60, 60, 1, 71, 59, 56, 69, 56]\n",
            "hii there\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenise entire training set of the Bible\n",
        "\n",
        "Using the PyTorch Library\n",
        "\n",
        "Get all the text\n",
        "\n",
        "Enocode it\n",
        "\n",
        "Wrap it in a torch.tensor\n",
        "\n",
        "Remember here each character is being tokenised"
      ],
      "metadata": {
        "id": "1iRrq1XlvsYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "print(data.shape, data.type)\n",
        "print(data[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-3La2ZP6vGx",
        "outputId": "9b0dba32-4364-4b0f-e146-726739934029"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4623633]) <built-in method type of Tensor object at 0x7a560a5a9f80>\n",
            "tensor([32, 65,  1, 71, 59, 56,  1, 53, 56, 58, 60, 65, 65, 60, 65, 58,  1, 30,\n",
            "        66, 55,  1, 54, 69, 56, 52, 71, 56, 55,  1, 71, 59, 56,  1, 59, 56, 52,\n",
            "        73, 56, 65, 70,  1, 52, 65, 55,  1, 71, 59, 56,  1, 56, 52, 69, 71, 59,\n",
            "        10,  1,  9,  9,  1, 58, 56, 65, 56, 70, 60, 70,  1, 12, 21, 12,  0, 10,\n",
            "         0, 43, 59, 56,  1, 56, 52, 69, 71, 59,  1, 74, 52, 70,  1, 57, 66, 69,\n",
            "        64, 63, 56, 70, 70,  1, 52, 65, 55,  1, 73, 66, 60, 55,  8,  1, 52, 65,\n",
            "        55,  1, 55, 52, 69, 62, 65, 56, 70, 70,  1, 74, 52, 70,  1, 66, 73, 56,\n",
            "        69,  1, 71, 59, 56,  1, 70, 72, 69, 57, 52, 54, 56,  1, 66, 57,  1, 71,\n",
            "        59, 56,  1, 55, 56, 56, 67,  8,  1, 52, 65, 55,  1, 71, 59, 56,  1, 42,\n",
            "        67, 60, 69, 60, 71,  1, 66, 57,  1, 30, 66, 55,  1, 74, 52, 70,  1, 64,\n",
            "        66, 73, 60, 65, 58,  1, 66, 73, 56, 69,  1, 71, 59, 56,  1, 70, 72, 69,\n",
            "        57, 52, 54, 56,  1, 66, 57,  1, 71, 59, 56,  1, 74, 52, 71, 56, 69, 70,\n",
            "        10,  1,  9,  9,  1, 58, 56, 65, 56, 70, 60, 70,  1, 12, 21, 13,  0, 10,\n",
            "         0, 43, 59, 56, 65,  1, 30, 66, 55,  1, 70, 52, 60, 55,  8,  1,  3, 35,\n",
            "        56, 71,  1, 71, 59, 56, 69, 56,  1, 53, 56,  1, 63, 60, 58, 59, 71,  3,\n",
            "        22,  1, 52, 65, 55,  1, 71, 59, 56, 69, 56,  1, 74, 52, 70,  1, 63, 60,\n",
            "        58, 59, 71, 10,  1,  9,  9,  1, 58, 56, 65, 56, 70, 60, 70,  1, 12, 21,\n",
            "        14,  0, 10,  0, 30, 66, 55,  1, 70, 52, 74,  1, 71, 59, 52, 71,  1, 71,\n",
            "        59, 56,  1, 63, 60, 58, 59, 71,  1, 74, 52, 70,  1, 58, 66, 66, 55, 22,\n",
            "         1, 52, 65, 55,  1, 30, 66, 55,  1, 70, 56, 67, 52, 69, 52, 71, 56, 55,\n",
            "         1, 71, 59, 56,  1, 63, 60, 58, 59, 71,  1, 57, 69, 66, 64,  1, 71, 59,\n",
            "        56,  1, 55, 52, 69, 62, 65, 56, 70, 70, 10,  1,  9,  9,  1, 58, 56, 65,\n",
            "        56, 70, 60, 70,  1, 12, 21, 15,  0, 10,  0, 30, 66, 55,  1, 54, 52, 63,\n",
            "        63, 56, 55,  1, 71, 59, 56,  1, 63, 60, 58, 59, 71,  1, 55, 52, 76,  8,\n",
            "         1, 52, 65, 55,  1, 71, 59, 56,  1, 55, 52, 69, 62, 65, 56, 70, 70,  1,\n",
            "        31, 56,  1, 54, 52, 63, 63, 56, 55,  1, 65, 60, 58, 59, 71, 10,  1, 24,\n",
            "        65, 55,  1, 71, 59, 56, 69, 56,  1, 74, 52, 70,  1, 56, 73, 56, 65, 60,\n",
            "        65, 58,  1, 52, 65, 55,  1, 71, 59, 56, 69, 56,  1, 74, 52, 70,  1, 64,\n",
            "        66, 69, 65, 60, 65, 58,  8,  1, 66, 65, 56,  1, 55, 52, 76, 10,  1,  9,\n",
            "         9,  1, 58, 56, 65, 56, 70, 60, 70,  1, 12, 21, 16,  0, 10,  0, 43, 59,\n",
            "        56, 65,  1, 30, 66, 55,  1, 70, 52, 60, 55,  8,  1,  3, 35, 56, 71,  1,\n",
            "        71, 59, 56, 69, 56,  1, 53, 56,  1, 52, 65,  1, 56, 75, 67, 52, 65, 70,\n",
            "        56,  1, 60, 65,  1, 71, 59, 56,  1, 64, 60, 55, 70, 71,  1, 66, 57,  1,\n",
            "        71, 59, 56,  1, 74, 52, 71, 56, 69, 70,  8,  1, 52, 65, 55,  1, 63, 56,\n",
            "        71,  1, 60, 71,  1, 70, 56, 67, 52, 69, 52, 71, 56,  1, 71, 59, 56,  1,\n",
            "        74, 52, 71, 56, 69, 70,  1, 57, 69, 66, 64,  1, 71, 59, 56,  1, 74, 52,\n",
            "        71, 56, 69, 70, 10,  3,  1,  9,  9,  1, 58, 56, 65, 56, 70, 60, 70,  1,\n",
            "        12, 21, 17,  0, 10,  0, 30, 66, 55,  1, 64, 52, 55, 56,  1, 71, 59, 56,\n",
            "         1, 56, 75, 67, 52, 65, 70, 56,  8,  1, 52, 65, 55,  1, 70, 56, 67, 52,\n",
            "        69, 52, 71, 56, 55,  1, 71, 59, 56,  1, 74, 52, 71, 56, 69, 70,  1, 74,\n",
            "        59, 60, 54, 59,  1, 74, 56, 69, 56,  1, 53, 56, 63, 66, 74,  1, 71, 59,\n",
            "        56,  1, 56, 75, 67, 52, 65, 70, 56,  1, 57, 69, 66, 64,  1, 71, 59, 56,\n",
            "         1, 74, 52, 71, 56, 69, 70,  1, 74, 59, 60, 54, 59,  1, 74, 56, 69, 56,\n",
            "         1, 52, 53, 66, 73, 56,  1, 71, 59, 56,  1, 56, 75, 67, 52, 65, 70, 56,\n",
            "        22,  1, 52, 65, 55,  1, 60, 71,  1, 74, 52, 70,  1, 70, 66, 10,  1,  9,\n",
            "         9,  1, 58, 56, 65, 56, 70, 60, 70,  1, 12, 21, 18,  0, 10,  0, 30, 66,\n",
            "        55,  1, 54, 52, 63, 63, 56, 55,  1, 71, 59, 56,  1, 56, 75, 67, 52, 65,\n",
            "        70, 56,  1, 59, 56, 52, 73, 56, 65, 10,  1, 24, 65, 55,  1, 71, 59, 56,\n",
            "        69, 56,  1, 74, 52, 70,  1, 56, 73, 56, 65, 60, 65, 58,  1, 52, 65, 55,\n",
            "         1, 71, 59, 56, 69, 56,  1, 74, 52, 70,  1, 64, 66, 69, 65, 60, 65, 58,\n",
            "         8,  1, 52,  1, 70, 56, 54, 66, 65, 55,  1, 55, 52, 76, 10,  1,  9,  9,\n",
            "         1, 58, 56, 65, 56, 70, 60, 70,  1, 12, 21, 19,  0, 10,  0, 43, 59, 56,\n",
            "        65,  1, 30, 66, 55,  1, 70, 52, 60, 55,  8,  1,  3, 35, 56, 71,  1, 71,\n",
            "        59, 56,  1, 74, 52, 71, 56, 69, 70,  1, 53, 56, 63, 66, 74,  1, 71, 59,\n",
            "        56,  1, 59, 56, 52, 73, 56, 65, 70,  1, 53, 56,  1, 58, 52, 71, 59, 56,\n",
            "        69, 56, 55,  1, 60, 65, 71, 66,  1, 66])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seperate dataset into train, validation and testing split\n",
        "\n",
        "Keep the validation data aside to ensure the model is not just \"perfectly\" memorising\n",
        "\n",
        "Goal: Neural network that sort of creates Bible like text to hopefully understand the linguistic patterns within the Bible for deeper study"
      ],
      "metadata": {
        "id": "oATI6Urz7FIJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_index_cut = int( 0.64 * len(data) )\n",
        "val_index_cut = int( 0.8 * len(data) )\n",
        "\n",
        "# training data for the transformer\n",
        "train_data = data[:train_index_cut]\n",
        "val_data = data[train_index_cut:val_index_cut]\n",
        "test_data = data[val_index_cut:]"
      ],
      "metadata": {
        "id": "_p8Ej_Ml8R--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now plug some chunks of data into the Transformer\n",
        "\n",
        "Sample random little chunks of the training set\n",
        "\n",
        "Training a chunk at a time\n",
        "\n",
        "Maximum chunk length is called block size in code (typically)\n",
        "\n",
        "Sometimes block size is also called context length"
      ],
      "metadata": {
        "id": "xccZ4py69jBy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# start with a context_length aka block_size of 8\n",
        "\n",
        "context_length = 8\n",
        "\n",
        "block_size = context_length # to prevent any confusion later on"
      ],
      "metadata": {
        "id": "nP-GIKou-L5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Context length number of examples of next token in this context (character) prediction, hence the length context_length+1\n",
        "\n",
        "To be more precisie predicting position 2, 3, 4 all the way up to 9"
      ],
      "metadata": {
        "id": "yxqsw6SZN0IJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[:context_length+1]\n",
        "\n",
        "# 8 indi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSE6JWvkNQr-",
        "outputId": "3a8e774a-5084-453a-dd23-9fbe323c3119"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([32, 65,  1, 71, 59, 56,  1, 53, 56])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "X = input to the transformer (of length context_length)\n",
        "\n",
        "y = target for each position in the input X (still of length context_length)\n",
        "\n",
        "Iterate over all parts of the context length\n",
        "\n",
        "Think of it as the time dimension"
      ],
      "metadata": {
        "id": "TV4RrBPKOO-E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = train_data[:context_length]\n",
        "y = train_data[1:context_length+1]\n",
        "\n",
        "print(f\"Below are the {context_length} examples hidden in a chunk of {context_length+1} characters\")\n",
        "print(\"These have been sampled from the training set\")\n",
        "print(f\"Here is the sample: {train_data[:context_length+1]}\\n\")\n",
        "\n",
        "for position_index in range(context_length):\n",
        "  # characters in X up to position_index and including position_index\n",
        "  context = X[:position_index+1]\n",
        "  target = y[position_index]\n",
        "  print(f\"when input is {context} the taget is: {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBReQI78NUwV",
        "outputId": "1e776805-9e82-4080-943e-3073a9d83b41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below are the 8 examples hidden in a chunk of 9 characters\n",
            "These have been sampled from the training set\n",
            "Here is the sample: tensor([32, 65,  1, 71, 59, 56,  1, 53, 56])\n",
            "\n",
            "when input is tensor([32]) the taget is: 65\n",
            "when input is tensor([32, 65]) the taget is: 1\n",
            "when input is tensor([32, 65,  1]) the taget is: 71\n",
            "when input is tensor([32, 65,  1, 71]) the taget is: 59\n",
            "when input is tensor([32, 65,  1, 71, 59]) the taget is: 56\n",
            "when input is tensor([32, 65,  1, 71, 59, 56]) the taget is: 1\n",
            "when input is tensor([32, 65,  1, 71, 59, 56,  1]) the taget is: 53\n",
            "when input is tensor([32, 65,  1, 71, 59, 56,  1, 53]) the taget is: 56\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This gives the transformer familiarity with seeing different sized context sizes and still predicting the output correctly\n",
        "\n",
        "Note: during inference, the transformer never receives more than the context length so trailing parts are truncated"
      ],
      "metadata": {
        "id": "jv8ZprE5Q2ab"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The batch dimension\n",
        "\n",
        "Stacked up chunks for efficiency\n",
        "\n",
        "Keeps the GPUs busy, as they are good at parallel processing\n",
        "\n",
        "TLDR; processing multiple chunks all at the same time (but also those chunks are processed independently, they do not talk to each other)"
      ],
      "metadata": {
        "id": "xo4A8d05RamH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sampling random locations\n",
        "# so to make experiments reproducible later on, set a random seed\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "# the number of independent sequences we are processing\n",
        "batch_size = 4\n",
        "\n",
        "# maximum context length\n",
        "block_size = 8\n",
        "\n",
        "# how we get a batch for any arbitrary split\n",
        "def get_batch(split):\n",
        "\n",
        "  # generate a small batch of data of inputs x and targets y\n",
        "  # this results in a data array\n",
        "  data = train_data if split == \"train\" else val_data if split == \"val\" else test_data\n",
        "\n",
        "  # generate random positions to grab a chunk out of\n",
        "  # this is a random integer from 0 to length of data - block size (to prevent overshooting)\n",
        "  # get batch size of number of these random integers (random offsets)\n",
        "  # random offsets into the appropriate dataset (ie training set)\n",
        "  ix = torch.randint(low=0, high=len(data)-block_size, size=(batch_size,)) # outputs a list/tensor\n",
        "\n",
        "  x = torch.stack(\n",
        "      [ data[ random_offset : random_offset + block_size] for random_offset in ix ]\n",
        "  )\n",
        "\n",
        "  # get the corresponding target\n",
        "  y = torch.stack(\n",
        "      [ data[ random_offset+1 : random_offset + block_size + 1 ] for random_offset in ix ]\n",
        "  )\n",
        "\n",
        "  # torch.stack: stack up as rows\n",
        "  return x, y\n",
        "\n",
        "# sample\n",
        "# shape is rows=batch_size x column=block_sizeAkaContextLength\n",
        "xb, yb = get_batch(\"train\")\n",
        "print(\"inputs:\")\n",
        "print(xb.shape)\n",
        "print(xb)\n",
        "print(\"targets:\")\n",
        "print(yb.shape)\n",
        "print(yb)\n",
        "\n",
        "print(\"---\")\n",
        "\n",
        "for batch_index in range(batch_size): # batch dimension\n",
        "  for t in range(block_size): # time dimension (context length)\n",
        "    # include the corresponding batch index\n",
        "    context = xb[ batch_index, :t+1 ]\n",
        "    target = yb[ batch_index, t ]\n",
        "    print(f\"when input is {context.tolist()} the target: {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9coYamjRaI9",
        "outputId": "cc8b3eda-c989-47ae-8935-09cb4d0b785a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs:\n",
            "torch.Size([4, 8])\n",
            "tensor([[56, 54, 66, 65, 55,  1, 55, 52],\n",
            "        [69,  1, 74, 60, 71, 59,  1, 60],\n",
            "        [66, 70, 59, 72, 52,  1, 70, 52],\n",
            "        [ 1, 54, 59, 52, 65, 58, 56, 55]])\n",
            "targets:\n",
            "torch.Size([4, 8])\n",
            "tensor([[54, 66, 65, 55,  1, 55, 52, 76],\n",
            "        [ 1, 74, 60, 71, 59,  1, 60, 71],\n",
            "        [70, 59, 72, 52,  1, 70, 52, 60],\n",
            "        [54, 59, 52, 65, 58, 56, 55,  1]])\n",
            "---\n",
            "when input is [56] the target: 54\n",
            "when input is [56, 54] the target: 66\n",
            "when input is [56, 54, 66] the target: 65\n",
            "when input is [56, 54, 66, 65] the target: 55\n",
            "when input is [56, 54, 66, 65, 55] the target: 1\n",
            "when input is [56, 54, 66, 65, 55, 1] the target: 55\n",
            "when input is [56, 54, 66, 65, 55, 1, 55] the target: 52\n",
            "when input is [56, 54, 66, 65, 55, 1, 55, 52] the target: 76\n",
            "when input is [69] the target: 1\n",
            "when input is [69, 1] the target: 74\n",
            "when input is [69, 1, 74] the target: 60\n",
            "when input is [69, 1, 74, 60] the target: 71\n",
            "when input is [69, 1, 74, 60, 71] the target: 59\n",
            "when input is [69, 1, 74, 60, 71, 59] the target: 1\n",
            "when input is [69, 1, 74, 60, 71, 59, 1] the target: 60\n",
            "when input is [69, 1, 74, 60, 71, 59, 1, 60] the target: 71\n",
            "when input is [66] the target: 70\n",
            "when input is [66, 70] the target: 59\n",
            "when input is [66, 70, 59] the target: 72\n",
            "when input is [66, 70, 59, 72] the target: 52\n",
            "when input is [66, 70, 59, 72, 52] the target: 1\n",
            "when input is [66, 70, 59, 72, 52, 1] the target: 70\n",
            "when input is [66, 70, 59, 72, 52, 1, 70] the target: 52\n",
            "when input is [66, 70, 59, 72, 52, 1, 70, 52] the target: 60\n",
            "when input is [1] the target: 54\n",
            "when input is [1, 54] the target: 59\n",
            "when input is [1, 54, 59] the target: 52\n",
            "when input is [1, 54, 59, 52] the target: 65\n",
            "when input is [1, 54, 59, 52, 65] the target: 58\n",
            "when input is [1, 54, 59, 52, 65, 58] the target: 56\n",
            "when input is [1, 54, 59, 52, 65, 58, 56] the target: 55\n",
            "when input is [1, 54, 59, 52, 65, 58, 56, 55] the target: 1\n"
          ]
        }
      ]
    }
  ]
}